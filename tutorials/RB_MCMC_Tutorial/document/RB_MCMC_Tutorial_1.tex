\documentclass[11pt]{article}
\input{preamble}
\usepackage{framed}
\usepackage[]{listings}
\usepackage{fontspec}
\usepackage{placeins}
\usepackage{epstopdf}
\usepackage{hyperref}

\lstset{breaklines=true}

\definecolor{shadecolor}{RGB}{238,224,229}


\setlength{\topmargin}{-0.4in}
\setlength{\headheight}{14.5pt}
\pagestyle{fancy}

\newcommand{\taha}[1]{{\textcolor{red}{[TAH comment: #1]}}} % TAH comment

\titlespacing{\section}{0pt}{*0}{*0}
\titlespacing{\subsection}{0pt}{*0}{*0}
\titlespacing{\subsubsection}{0pt}{*0}{*0}

\titleformat{\section}
  {\normalfont\Large\bfseries\color{mycol}}
  {\thesection}{1em}{}

\titleformat{\subsection}
  {\normalfont\large\bfseries\color{mycol}}
  {\thesubsection}{1em}{}

\titleformat{\subsubsection}
  {\normalfont\bfseries\color{mycol}}
  {\thesubsection}{1em}{}

% command for MrBayes command-line step
\newcommand{\cl}[1]{{\texttt{\textbf{#1}}}}

\newcommand{\colx}[1]{{\textcolor{tcol}{#1}}}

\newcommand{\mbcl}[1]{\exs{\cl{MrBayes > {#1}}}}

\newcommand{\rbprmt}{RevBayes > } 
\newcommand{\rbcl}[1]{\exs{\cl{\rbprmt{#1}}}}
\newcommand{\rbout}[1]{\exs{\cl{\textcolor{outputcol}{#1}}}}
\newcommand{\rbdn}{{\Large \symbol{126}}} % This makes a copy/pasteable tilde
\newcommand{\rbclml}[1]{\exs{\cl{\ \ \ \ \ \ \ \ \ \ \ {#1}}}}

% text box settings
% requires compiling w/ XeLaTeX
\newfontfamily\listingsfont[Scale=1.0]{Courier New}
\lstset{basicstyle=\listingsfont, columns=texcl}
\defaultfontfeatures{Mapping=tex-text}


\makeatletter
\lst@CCPutMacro\lst@ProcessOther {"2D}{\lst@ttfamily{-{}}{-{}}}
\@empty\z@\@empty
\makeatother

\begin{document}
\renewcommand{\headrulewidth}{0.5pt}
\headsep = 20pt
\lhead{ }
\rhead{\textsc {RevBayes Tutorial --- Substitution Models}}

\thispagestyle{plain}
\begin{center}

\textbf{\LARGE Phylogenetic Inference using RevBayes}\\\vspace{2mm}
\textbf{\it{\Large Substitution Models}}\\\vspace{2mm}
\end{center}

\section*{Overview}


This tutorial demonstrates how to set up and perform an analysis for different substitution models. 
You will create a phylogenetic model for the evolution of DNA sequences under a JC, HKY85, GTR, GTR+Gamma and GTR+Gamma+I substitution model.
For all these models you will perform an MCMC run to estimate phylogeny and other model parameters.

\subsection*{Requirements}
We assume that you have completed the following tutorials:
\begin{itemize}
\item RB\_Basics\_Tutorial
\end{itemize}



%
%\subsection*{Analysis Functions}
%
\newpage
\FloatBarrier
\section{Exercise: Character Evolution under various Substitution Models}

%\subsection{Introduction}
%
%
%\bigskip
%\section{Model Selection \& Partitioning using Bayes Factors}

``{\it You can never be absolutely certain that the MCMC is reliable, you can only identify when something has gone wrong.}'' Andrew Gelman

\bigskip
Model-based inference is, after all, based on the model.
Careful research means being vigilant both regarding the choice of model and rigorously assessing our ability to estimate under the chosen model. The first issue---model specification, which actually entails three closely related issues---is critically important for the simple reason that unbiased estimates can only be obtained under a model that provides a reasonable description of the process that gave rise to our data. {\it Model selection} entails assessing the {\it relative fit} of our dataset to a pool of candidate models. Rankings are based on model-selection methods that compare the relative fit of candidate modes based either on their maximum-likelihood estimates (which measures the fit of the data to the model at a single point in parameter space), or on marginal likelihood of the candidate models (which measures the average fit of the candidate models to the data). {\it Model adequacy}---an equally important but relatively neglected issue---assesses the absolute fit of the data to the model. {\it Model uncertainty} is related to the common (and commonly ignored) scenario when multiple candidate models provide a similar fit to the data: in this scenario, conditioning on {\it any single} model (even the best) will lead to biased estimates, and so model averaging is required to accommodate uncertainty in the choice of model.

Much less concern is given to the second aspect of model-based inference: the ability to obtain reliable estimates under the chosen model(s). The implicit assumption, it seems, is that if a model is implemented correctly, and if that implementation is  successfully used to obtain an estimate from a given dataset, then we must have performed valid inference under the model. This would be perfectly sound reasoning if inferences were based on analytical methods. Owing to the complexity of the models, however, it is not possible to estimate phylogenetic parameters analytically. Instead, parameter estimates are based on numerical methods. In the case of maximum-likelihood estimation, these are typically hill-climbing algorithms that attempt to search the profile likelihood to identify the vector of point estimates of all phylogenetic model parameters that jointly maximize the likelihood of observing the data under the model. The reliability of these algorithms can (and should) be assessed by comparing estimates obtained from repeated analyses that are initiated from random points in parameter space. Because there is only one {\it maximum} likelihood estimate, the terminal values estimated by replicate runs should be identical (within the precision of computer memory).

In the Bayesian statistical framework, inferences focus on the joint posterior probability density of phylogenetic model parameters, which is approximated by Markov chain Monte Carlo (MCMC) algorithms. It may be comforting to know that, in theory, an {\it appropriately constructed} and {\it adequately run} MCMC simulation is guaranteed to provide an arbitrarily precise description of the joint posterior probability density. In practice, however, even a given MCMC algorithm that provides reliable estimates in {\it most} cases will nevertheless fail in {\it some} cases and is not guaranteed to work for any given dataset. This raises an obvious question: ``When do we know that an MCMC algorithm provides reliable estimates for a given empirical analyses''. The answer is simple: Never.
%[Leaving aside, for the moment, questions regarding the definitions of an {\it appropriately constructed} and {\it adequately run} chain.] 

Fortunately, this problem is not unique to the field of phylogenetics. Much of Bayesian inference outside our field also relies on MCMC algorithms to approximate the joint posterior probability density of parameters: similar concerns regarding the reliability of those inferences has motivated the development of a suite of diagnostic tools to assess MCMC performance. The trick is learning how to use these tools effectively and rigorously, especially for analyses that entail complex phylogenetic models and/or large datasets.

\bigskip
\subsection{MCMC Basics}

The ability to rigorously diagnose MCMC performance requires familiarity with some basic concepts from probability theory (discussed last time) and a strong intuitive understanding of the underlying mechanics---we need to know how the algorithms work in order to understand when they are not working. In this installment we’ll briefly cover the mechanics of the Metropolis Hastings MCMC algorithm.

Recall that Bayesian inference is focused on the posterior probability density of parameters.
The posterior probability of the parameters can, in principle, be solved using Bayes’ theorem.
However, (most) phylogenetic problems cannot be solved analytically, owing mainly to the denominator of Bayes’ theorem---the marginal likelihood requires solving multiple integrals (for all of the continuous parameters, such as branch lengths, substitution rates, stationary frequencies, etc.) for each tree, and summing over all trees.

Accordingly, Bayesian inference of phylogeny typically resorts to numerical methods that approximate the posterior probability density. There are many flavors of Markov chain Monte Carlo (MCMC) algorithms—Gibbs samplers, Metropolis-coupled and reversible-jump MCMC, etc.—we will consider the Metropolis Hastings (MH) algorithm because it is commonly used for phylogenetic problems, and because it is similar to many other variants (which we will cover elsewhere). Note that MCMC and Bayesian inference are distinct animals: they have a relationship similar to that between ’optimization algorithms’ and ‘maximum-likelihood estimation.’ Some Bayesian inference can be accomplished without MCMC algorithms, and MCMC algorithms can be used to solve problems in non-Bayesian statistical frameworks.

To introduce the MH algorithm, we will imagine a robot that is programed to explore an area. Specifically, the goal of our robot is to generate a topographic map of an unknown terrain. This terrain has a total surface area of one hectare. We deploy our robot by parachute at a random location within the terrain. We have programmed the robot with three simple rules:

\begin{enumerate}
\item{If a proposed step will take the robot uphill, it automatically takes the proposed step.}

\item{If a proposed step will take the robot downhill, it divides the elevation of the proposed location by the elevation of the current location: we call this quotient R. It then generates a uniform random number, $U[0,1]$. If $U<R$, the robot takes the proposed step; otherwise, it stays put.}

\item{The distribution for proposing steps is symmetrical. That is, the probability of proposing a step (but not necessarily accepting a proposed step) from point A to point B is equal to the probability of proposing a step from point B to point A.}
\end{enumerate}

We allow our little robot to wander through the terrain following these three simple rules. At prescribed intervals (e.g., every 10 proposed steps), the robot records the details of his position (his elevation, latitude, longitude, etc.) in a log. If we allow our robot to wander long enough, his log is guaranteed to provide an arbitrarily precise description of the topography of the terrain. 

Let’s consider a slightly more formal description of the Metropolis-Hastings MCMC algorithm. First some preliminaries. This algorithm entails simulating a Markov chain that has a stationary distribution that is the joint posterior probability density of phylogenetic model parameters. The `state’ of the chain is a set of parameter values that fully specify phylogenetic model: e.g., a tree topology, a vector of branch lengths, and a set of parameters specifying the stochastic model of trait change (e.g., for the GTR + $\Gamma$  substitution model, this comprises a vector of values for the four stationary frequencies, a vector of values for the six exchangeability parameters, and the value of the alpha parameter describing the shape of the gamma-distributed among-site rate variation). Under the robot analogy, the state of the chain corresponds to a unique point in the terrain. The Markov property of the MCMC reflects the fact that the next state of the chain only depends on the current state of the chain, but not on previous states—that is, the past affects the future only through the present. The Monte Carlo aspect of the MCMC reflects the fact that it is a simulation: it is a numerical method that relies on repeated random sampling.

Now, on to the MH algorithm:

\begin{enumerate}
\item{Initialize the chain with values for all parameters, including the tree topology, $\tau$ , the vector of branch lengths $\nu$ , and substitution model parameters $\pi_i$, $q_i$, $\alpha$. We will call the set of model parameters $\theta$ . The initial parameter values might be specified arbitrarily, or might be drawn from the corresponding prior probability density for each parameter.}

\item{Select a single parameter (or set of parameters) to alter according to its proposal probability. For example, here are the default proposal probabilities used by \verb!MrBayes!\:
      The MCMC sampler will use the following moves:
         With prob.  Chain will use move
            1.00 \%   Dirichlet(Revmat)\\
            1.00 \%   Slider(Revmat)\\
            1.00 \%   Dirichlet(Pi)\\
            1.00 \%   Slider(Pi)\\
            2.00 \%   Multiplier(Alpha)\\
           10.00 \%   ExtSPR(Tau,V)\\
           10.00 \%   ExtTBR(Tau,V)\\
           10.00 \%   NNI(Tau,V)\\
           10.00 \%   ParsSPR(Tau,V)\\
           40.00 \%   Multiplier(V)\\
           10.00 \%   Nodeslider(V)\\
            4.00 \%   TLMultiplier(V)\\

We can see that $\sim 1\%$ of the time ({\it i.e.}, with probability $\sim 0.01$), the MCMC will propose changes to the exchangeability (`revmat’) and stationary frequency (`pi’) parameters using a `Dirichlet' proposal mechanism, and an equal effort proposing changes to the same parameters using something called a `Slider’ proposal mechanism. Conversely, $\sim 10\%$ of the time ({\it i.e.}, with probability $\sim 0.1$), the MCMC will propose changes to the tree and branch lengths (`Tau and V’) using the `extending SPR’ proposal mechanism, and with equal probability using the `extending TBR’, `extending NNI’ and the `parsimony SPR’ proposal mechanisms.

For the moment, we won’t worry about the details of these proposal mechanisms—they basically involve different ways of `poking’ the current parameter value, $\theta$, to generate a new (proposed) parameter value, $\theta ^{\prime}$. The important question at the moment is: Where do these proposal probabilities come from? The answer is: experience. We want to design the MCMC such that it invests effort in a given parameter in proportion to the difficulty of approximating that parameter. Note that the MCMC summarized above will spend $\sim 2\%$ of its time proposing changes to the exchangeability and stationary frequency parameters, but will invest $\sim 40\%$ of its time proposing changes to the topology parameter. Experience suggests that the tree topology is a more difficult parameter for the MCMC to approximate relative to the exchangeability and stationary frequency parameters (in fact, it appears that the developers of \verb!MrBayes! determined from their experience that the topology is $\sim 20$ times harder to approximate).}

\item{Propose a change to the selected parameter using the parameter-specific proposal
mechanism. Different parameters may naturally have different prior probability densities—for example, the stationary frequencies are proportions (ranging between 0 and 1), and so are conveniently described using a Dirichlet prior probability density, whereas the alpha-shape parameter can range between zero and infinity, so is better described using a uniform prior probability density. Different kinds of prior probability densities will have specific proposal mechanisms—for example, there is something called a `Dirichlet’ proposal mechanism that is used to propose new values for parameters described by a Dirichlet prior, and something called a `Slider’ proposal mechanism that is used to propose new values for parameters described by a uniform prior. (Again, we’ll go into the gory details of these proposal mechanisms another time. The main idea for now is that the proposal mechanisms generate a new parameter value by poking the current parameter value.)

The design of proposal mechanisms is something of a dark art—trial and error are used to guide the development of mechanisms that work well. Nevertheless, there are basic criteria that the proposal mechanisms must meet. All proposal mechanisms must be:

(i) stochastic (new parameter values must be proposed `randomly’)

(ii) irreducible (all parameter values must be potentially accessible by the chain)

(iii) aperiodic (the proposal mechanism must not induce epicycles of the chain)}

4. Calculate the probability of accepting the proposed change, $R$:

The acceptance probability, $R$, is either equal to one or the product of three ratios—so long as that product is less than one (because $R$ is a probability, so it cannot be greater than one). So, what are these three ratios?

Likelihood ratio: the likelihood ratio is simply the likelihood of the observations given the proposed value of the parameter, divided by the likelihood of the observations given the current value of the parameter. We can calculate the likelihood for any given parameterization of the phylogenetic model using the pruning (Felsenstein) algorithm.
Prior ratio: in Bayesian inference, each parameter is a random variable, and so is described by a prior probability density. Accordingly, we can `look up’ (calculate) the prior probability of any specific parameter value. The prior ratio is simply the prior probability of the proposed and current parameter values.
Proposal ratio: the proposal ratio is the probability of proposing the current parameter value given the proposed parameter value, divided by the converse. This is also called the Hastings ratio. This is equivalent to the rule that forces our robot to propose steps symmetrically; i.e., that the probability of proposing a step from point A to point B in the terrain is equal to the probability of proposing a step from point B to point A. For inference problems in which the dimensions of the model are static, the proposal ratio is usually equal to one (we’ll discuss exceptions to this in the context of reversible-jump MCMC in a future post).

Note that if the proposal ratio is equal to one, the acceptance probability, $R$ is based only on the product of the likelihood and prior ratios. Does that ring a bell? [Hint: think of Bayes' theorem.] [Hint 2: think of the right side of Bayes' theorem.] [Hint 3: think of the numerator of the right side of Bayes' theorem.] That is, the posterior probability is proportional to the product of the likelihood and prior probability. Accordingly, the acceptance probability is the posterior probability of the proposed state divided by the posterior probability of the current state. Just as we programmed our robot, if the ratio of the proposed and current elevations (posterior probabilities) is greater than 1 (i.e., it is an uphill step), we always accept the proposed change. When the ratio of the proposed and current elevations is less than 1 (i.e., it is an downhill step), we may or may not take the proposed step (stay tuned).

5. Generate a uniform random number between zero and one, $U[0,1]$. If $U<R$, accept
the proposed change; otherwise, the current state of the chain becomes the next state of the chain. Downhill moves will be accepted `randomly’ in proportion to the difference in elevation.

6. Repeat steps $2-5$ an `adequate’ number of times.

That’s it! Notice that the decision to accept or reject proposed steps in the MCMC (and thus to sample from the joint posterior probability density) is based exclusively on the likelihood and prior probability of the proposed and current states—two quantities that are easy to calculate. The beautiful, fantabulous achievement of the Metropolis-Hastings algorithm is the slaying of the beastly denominator of Bayes’ theorem. Specifically, the algorithm allows us to do inference while entirely avoiding the need to calculate the (completely intractable) marginal likelihood!

Approximating the joint posterior probability density is based on samples from the MCMC: a chain following the simple rules outlined above will sample parameter values in proportion to their posterior probability. That is, the proportion of time that the chain spends in any particular state is a valid approximation of the posterior probability of that state (e.g., if a clade is present in $87\%$ of the samples drawn from the chain, then the posterior probability of that clade is estimated to be $0.87$).

Why do we accept proposals to states with lower posterior probability? People familiar with maximum-likelihood estimation often misunderstand the purpose of accepting proposals to states with a lower posterior probability. In maximum-likelihood inference, the game is to simply climb relentlessly and mindlessly up the likelihood surface in search of the very tip of the globally highest peak. Accordingly, the only reason these zombie hill climbers might consider a downward move would be motivated by concerns that they were currently climbing up a local (rather than global) optimum. By contrast, Bayesians are not just interested in the elevation of the very tip of the absolute peak of the posterior probability surface, but rather are interested in exploring and estimating the entire joint posterior probability density—we want topographical map of the entire posterior probability, not the elevation of the tip of the very highest peak in parameter space.

This survey of the joint posterior probability density results in a more robust inference procedure (inferences are averaged over the joint posterior probability of all model parameters), and allows us to estimate and evaluate the marginal posterior probability density for each of the parameters (these can be viewed by querying the MCMC samples with respect to the parameter of interest—we will do this in future tutorials). Accordingly, it is not sufficient for the chain to reach the peak of the joint posterior probability density; we need the chain to mix over the entire stationary distribution, spending time at each location in proportion to its posterior probability.

Diagnosing MCMC performance. Next to the specification of priors (which are inspired by much more philosophical considerations), performance of the MCMC algorithm used to approximate the joint posterior probability distribution is the greatest concern associated with Bayesian inference (it is certainly a more general concern, as it holds even when the priors are uncontroversial, and, in my opinion, is a more legitimate and practical concern). There are three closely related issues associated with MCMC performance: (1) convergence (is the robot sampling from the stationary distribution); (2) mixing (is the robot efficiently moving over the posterior probability density); and (3) adequacy (has the robot collected sufficient samples from the target distribution to describe it adequately). We’ll address these issues in future posts.

\end{enumerate}


\bigskip
\subsection{Getting Started}

For the exercises outlined in this tutorial, we will use \RevBayes~interactively by typing commands in the command-line console.
The format of this exercise uses \colorbox{shadecolor}{\tt lavender blush shaded boxes} to delineate important steps. 
The various \RevBayes~commands and syntax are specified using \cl{typewriter text}. 
And the specific commands that you should type (or copy/paste) into \RevBayes~are indicated by shaded box and prompt. 
For example, after opening the \RevBayes~program, you can load your data file:

{\tt \begin{snugshade*}
\begin{lstlisting}
RevBayes > data_ITS <- readCharacterData("data/fagus_ITS.nex")
\end{lstlisting}
\end{snugshade*}}

For this command, type in the command and its options:\\ \cl{data\_ITS <- readCharacterData("data/fagus\_ITS.nex")}. 
\textbf{DO NOT} type in ``\cl{RevBayes >}'', the prompt is simply included to replicate what you see on your screen. 

This tutorial also includes hyperlinks: bibliographic citations are {\textcolor{citescol}{burnt orange}} and link to the full citation in the references, external URLs are {\textcolor{urlscol}{cerulean}}, and internal references to figures and equations are {\textcolor{linkscol}{purple}}.

The various exercises in this tutorial take you through the steps required to perform phylogenetic analyses of the example datasets. 
In addition, we have provided the output files for every exercise so you can verify your results. (Note that since the MCMC runs you perform will start from different random seeds, the output files resulting from your analyses \textit{will not} be identical to the ones we provide you.)

\exs{Download data and output files from:\\ \href{https://www.nescent.org/sites/academy/RevBayes\_Workshop\_Schedule}{https://www.nescent.org/sites/academy/RevBayes\_Workshop\_Schedule}
%\href{http://treethinkers.org/phylogenetic-inference-using-mrbayes-v3-2/}{\small link}
}


\exs{Open the file \cl{data/fagus\_ITS.nex} in your text editor. This file contains the sequences for the ITS gene sampled from 13 species (Box 1). The elements of the \cl{DATA} block indicate the type of data, number of taxa, and length of the sequences.}


\begin{center}
Box 1: A fragment of the NEXUS file containing the ITS sequences for this exercise. \\
\end{center}
{\tt \scriptsize \begin{framed}
\begin{lstlisting}
#NEXUS 

Begin data;
Dimensions ntax=13 nchar=673;
Format datatype=DNA missing=? gap=-;
Matrix
Trig_excelsa   
TCGAAACCTG...
Fagus_engleriana   
TCGAAACCTG...
Fagus_crenata1   
TCGAAACCTG...
Fagus_japonica2   
TCGAAACCTG...
Fagus_japonica1   
TCGAAACCTG...
Fagus_orientalis   
TCGAAACCTG...
Fagus_sylvatica   
TCGAAACCTG...
Fagus_lucida1   
TCGAAACCTG...
Fagus_lucida2   
TCGAAACCTG...
Fagus_crenata2   
TCGAAACCTG...
Fagus_grandifolia   
TCGAAACCTG...
Fagus_mexicana   
TCGAAACCTG...
Fagus_longipetiolata   
TCGAAACCTG...
	;
End;
\end{lstlisting}
\end{framed}}

\exs{Also note that ``pre-cooked'' output files are provided in the download. Throughout this tutorial, you can use those files to summarize output if you do not have time to run the full analyses yourself.}

\bigskip
\section{Semi-automatic MCMC diagnosis: bonsai}

First, install the R package bonsai from source.
{\tt \begin{snugshade*}
\begin{lstlisting}
> install.packages('< path to bonsai >',repos=NULL,type='source',dependencies=TRUE)
> library(bonsai)
\end{lstlisting}
\end{snugshade*}}

Next, give the MCMC project a name. 
This ensures the document produced by bonsai has a unique name.
{\tt \begin{snugshade*}
\begin{lstlisting}
> project <- '< project name >'
\end{lstlisting}
\end{snugshade*}}

Now we need to tell bonsai where our log files are located.
We define a vector of paths for the posterior log files, and one for the prior log files.
{\tt \begin{snugshade*}
\begin{lstlisting}
> posteriors <- c('< path to posterior log file 1 >','< path to posterior log file 2 >','< path to posterior log file 3 >','< path to posterior log file 4 >')
> priors <- c('< path to prior log file 1 >','< path to prior log file 2 >','< path to prior log file 3 >','< path to prior log file 4 >')
\end{lstlisting}
\end{snugshade*}}

We also need to define a path for the output.
{\tt \begin{snugshade*}
\begin{lstlisting}
> path <- '< path to output diretory >'
\end{lstlisting}
\end{snugshade*}}

Finally, we create the bonsai object and execute the \texttt{runBonsai()} function.
{\tt \begin{snugshade*}
\begin{lstlisting}
> bonsai_object <- bonsai(project=project,path=path,posterior.paths=posteriors,prior.paths=priors)
> bonsai_object$runBonsai()
\end{lstlisting}
\end{snugshade*}}


%\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  REFERENCES  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\renewcommand{\bibsection}{\section*{Relevant References}}


\bibliography{bib_tex/master_refs}




\end{document}
