Subject:
Re: More on RevBayes
From:
Fredrik Ronquist <fredrik.ronquist@nrm.se>
Date:
Fri, 15 Jan 2010 15:19:30 +0100
To:
Sebastian Höhna <sebastian.hoehna@gmail.com>
CC:
John Huelsenbeck <johnh@berkeley.edu>, Maxim Teslenko <maxkth@gmail.com>

Hi Sebastian:

I will be arriving early tomorrow afternoon, I think, so hopefully we will have a chance to talk then. I have been in bed with a bad cold this week but I have had some time to make progress on the code nevertheless. The workspace is now initialized correctly in testParser and I can create constant nodes and stochastic nodes, call functions and clamp stochastic nodes. There is probably going to be a few minor glitches to address before the equation assignments work as well. I will keep you updated. As I mentioned, I work on my own branch for now, it is in branches/fredrik.

Some comments on some of the  previous points:

2. Like you, I support a global namespace with compact const strings. Low on my list of priorities right now, though.

3. I work on a separate branch now (called fredrik) and would like to do that until I have the mcmc chain running successfully on the normal model, created and read in through the language and the parser. We can worry about merging the dag node stuff when I have this running. I don't think the conflicts between our versions are too bad actually but I don't like to remove dag functionality that you are using but which is unnecessary in my model before I know for sure that my model works and that we all agree it is a good idea to keep the DAG lean.

5. Any other name would do... One can also discuss whether we want to have one interface class RbComplex, one base class for objects with members and methods and another one for objects with elements. Shouldn't be too difficult to change between these models, as we see fit.

8. It seems like a good point for future discussion, whether we want to have the statistics code in a separate file or in each of the 40-50 distribution classes we are likely to have eventually. With lnPdf, pdf, rv, cdf, quantile, priorRatio and likelihoodRatio functions implemented for all distributions, the RbStatistics class, if we use it, will be huge.

9. I think we are actually in agreement here, more or less, but my model extracts the affected stochastic nodes from the DAG first, so you can calculate the likelihood ratio from them using their distributions outside of the DAG. The distribution object itself can easily calculate and distinguish between the two ratios but maybe we still need some discussion before we agree on the names for the two functions. The first function takes two values (old and new values) and calculates a ratio, which I tentatively call the prior ratio, but which could also be called the pdf ratio. It is simply the ratio of the density for the old and new values given the current parameter values of the distribution. The second function takes a single value (current value) and calculates a ratio, which I tentatively call the likelihood ratio. It is the ratio of the density of a single observed value but given old and new parameter values of the distribution. The ratios correspond exactly to (factors of) the prior ratio and likelihood ratio, respectively, in the calculation of the acceptance ratio variable r.

10. My model should deal with the situation you are describing. For instance, branches on the same tree will necessarily be collected in a tree object, which will reside inside a deterministc DAG node. A block move attached to that deterministic node gets access to the tree, from which it can get access to all the stochastic nodes it wants to play with, be they branches, nodes, topologies or something else. That said, we may still need to make some special accommodation for trees, particularly in the calculation of probabilities. Unless we use a model similar to that suggested by Jordan, in which case it might not be necessary.

So far, my main problem with the parser code has been the static code used to add types, distributions and functions to the workspace. In my original mode, I was trying to find a way of adding each function (type, distribution...) using a line of static code calling a function in the the globalWorkspace instance of Workspace. This actually turns out to be very tricky because you cannot be guaranteed that variables are initialized in the right order. For example, you cannot rely on the global name constants defined in RbNames.h to be initialized in all functions executed statically. That is, incidentally, why our original static member variable model for the getClass() function would never have worked.  Just as an example, in getting the new version of the parser to run, I encountered problems with bugs in the static code where you jump from one function in which the constants in RbNames.h are initialized to another function where they are not initialized, so the program crashes. In principle, I think I can solve these problems (e.g. by using defines instead of constant strings) but it is difficult and dangerous code so I suggest we move to another model, which does not require any static code at all. Basically, it involves having an initializeGlobalworkspace function in Workspace.cpp, where we add in all functions and other things that need to be in the global workspace from the start. It involves exactly the same number of lines of code as the previous solution, the only difference is that you have to touch one extra file, namely Workspace.cpp. Since the current model only involves adding a header file and a source file regardless of whether you are adding a complex type with a constructor, a distribution with distribution functions and a constructor, or just a regular function, I think it is still quite manageable. Maybe you can come up with a way of adding in distributions, moves or other components without touching the Workspace.cpp file? I noticed you had been working on this previously.

Best

Fredrik

Sebastian Höhna skrev:
> Hi,
>
> I see it the same way that we are unfortunately not yet ready to demonstrate something in RevBayes or let people explore it. Anyway, here some comments to Fredrik's mail.
>
> I'm happy to talk about graphical models in phylogenetics. I'm not worried that anyone would "steal" our ideas and some of the faculty already know, at least partially, what we are up to. However, I'm not sure if it is sensible to give only a short introduction to such a abstract and comprehensible topic without giving people the opportunity to explore them themselfes.
> Maybe we can discuss this on Saturday?
>
> 1) I'm with it :)
> 2) I also prefer strings instead of defines but at least a global namespace for all of them.
> 3) I had some changes on the DAG-nodes as well but I haven't checked Fredrik's most recent version. I guess we should go over it a little bit again.
> 4) Sounds good.
> 5) I agree with the idea, I just stumbled a bit over the name of the class.
> 6) ok
> 7) ok
> 8) I actually don't mind as long as we do not replicate the code.
> 9) I see this point, however I think it is only possible to calculate the pdf-ratio, because the distribution doesn't know anything about prior or posterior. Therefore, if you need the prior ratio, then you ask for the pdf-ratio of the distribution of the dag node of the parameter. The likelihood ratio is given the same way but from the distribution of the dag node of the children (observation or further parameters). This results that distributions shouldn't distinguish between likelihood and prior, which is more the task of the dag to ask the correct distribution objects.
> 10) Again, I haven't seen the code but according to Fredrik's description I have one concern. If we allow for instance branch length being independent objects and therefore indepent parameters and dag nodes, then it might be nice to update a block of stochastic nodes as well. So I would like to also be able to block-update stochastic nodes.
> 11) That's fine with me.
>
> Regarding cmake, I was working over christmas on a way to edit only one master file, wich is in the main directory and should be the only one to edit when new classes are introduced. There, a variable called source is set with all sources needed. This can be used then in a single short line of code to create test cases. If you want to use only some specific sources then you need to edit the single cmake file and explicitly list the sources. If you sent me the current version of the manual/best practices I can write something about it in there.
>
>
> Cheers
> Sebastian
>
> On Tue, Jan 12, 2010 at 10:36 PM, Fredrik Ronquist <fredrik.ronquist@nrm.se> wrote:
>
>     Hi Gentlemen:
>
>     It has taken me much too long but now I have all the programming done (theoretically) to get the normal model to run through the parser and it all compiles and links (the code I am using, that is). The normal example actually exercises a lot of the parser code and most of the base classes we need in the program. There will obviously be a number of minor glitches and things to work out before it all runs; I hope to sort out those things in the next week or so. The test file I am using, specifying the normal model and the analysis, will be in the test/parser directory, together with the testParser executable.
>
>     I had hoped originally, as you know, that we could have something to show next week in Cesky Krumlov, but we are obviously not there just yet. It is important that we do not hurry too much through these stages in the project where we go back and forth a little on how to organize the base classes. It will pay off in the end, I am convinced, even if it is frustrating right now for all of us, especially for Sebastian I think. Even if we could have had a GTR model running next week, I don't think the students would have been particularly impressed without the ability to play around with the parser and different model specifications, and without access to help information. In addition, it just does not seem right to present such a powerful program in something like 15 to 20 minutes. Let's introduce RevBayes instead at a workshop that we organize in the summer, devoted entirely to RevBayes.
>
>     If Sebastian is interested, I would be happy to let him have about 20 minutes to talk about graphical model specifications in general and phylogenetic models in particular on Monday. But do you think it is wise to talk too much about our ideas now or should we wait until we are closer to publishing them?
>
>     Below is a quick run-down of the most important changes I have introduced in the RevBayes code. This should be the last time I make such large changes in the code.
>
>     1. Given that we calculated the number of argument rules in the C-style array twice in the code and did it incorrectly both times (!), I came to the conclusion that Sebastian was right in preferring an object-oriented solution so I use STL vector throughout now.
>
>     2. I like the compactness of the #defines in RbNames that John introduced but they are not as good as the old solution when you think about it. First, they do not reduce the memory footprint at all, they just insert replicate C strings all over the place. Second, you can't use them where you need STL strings. I converted the defines to const std::string, which is compact but does not have any of the drawbacks of the defines. Eventually we may want to hide them in one name space (RbNames) but I have not done that yet.
>
>     3. The dag structure is much better now I think. Constant nodes do not have parents so children nodes are now always variable nodes, only variable nodes need to know about keeping and restoring, only stochastic nodes need to know about likelihoods and priors etc. I managed to get most of the mcmc functions out of the dag, which I think is good. Eventually, I would like to remove also monitors and moves from the dag and place them in the mcmc object instead. Think about metropolis coupling, for instance, in which you may want to set moves and monitors separately for each chain. Or ML inference, for which moves in the DAG are irrelevant. It will not be difficult to associate the moves and monitors with the dag nodes in the mcmc object.
>
>     4. The model is now completely clean of mcmc functionality, which I think is good.
>
>     5. I introduced MemberObject, which is the base object for complex object with member variables and member functions that are exposed to the parser (the interface is defined in RbComplex). Look at distributions (exp, norm and unif) or moves to see examples of how you write derived classes exposed to the parser. I am pretty happy with this solution, it simplifies the programming of these objects quite a bit. The solution also deals with inheritance, function overloading, and quick repeat execution of member methods/functions with preprocessed arguments.
>
>     6. I introduced ConstructorFunction, which can be used to automatically create a constructor function for a complex object. It uses the rules (member rules) set up to manage the member variables. So, no need to write these functions unless you want to do something special.
>
>     7. I found a solution to automatically generate both distribution functions (pnorm, qnorm, rnorm etc) and distribution constructor functions (norm) automatically from the complex distribution object. I derive real-valued distribution objects from DistributionReal, which adds the p- and q- variants of the function (cdf and quantile).
>
>     8. I know John finds it convenient to have all the distribution functions in RbStatistics but I prefer to have them in the distribution objects themselves. For distributions like exp and unif, it seems silly to call a separate file for just one line of code.
>
>     9. I have the prior and likelihood ratio calculations done in the distribution objects. You can see even for the very simple distributions implemented so far that it is more efficient to calculate the ratios rather than calculating and storing the full probabilities. After all, this is one of the reasons MCMC works so well, that density ratios are easy to calculate.
>
>     10. Moves are now divided into SimpleMove and BlockMove (not programmed yet). The Simple moves are associated with stochastic nodes and do what you think. In line with the function solution, they get access to the Stochastic Node value so they can manipulate it rather than proposing an entirely new value, which involves construction and destruction. When the Move asks for a mutable value pointer, it gets the set of affected stochastic nodes in return. From these and the moved node itself, it is easy to calculate the prior and likelihood ratios. Block moves are associated with deterministic nodes and can get all the upstream stochastic nodes they need from the complex object inside the deterministic node. For instance, these stochastic nodes may include branches, nodes and topology from a tree object.
>
>     11. I have given the names quite a bit of thought. I do not like the Rb prefix so I have removed it from most classes except from some of the base objects and some utility objects, where I think it is needed or appropriate (like RbObject or RbNames). I like distributions, moves and functions to have similar names alluding to the function name or constructor function name. In general, I try to follow R or BUGS. For instance, the normal functions are termed "xnorm" in R, so I propose naming the distribution object "Dist_norm". Using the same ideas, the "source" function is named "Func_source". For the moves, I tried using names starting with m, e.g. "mscale" for the scale move. The class then becomes "Move_mscale" and the automatically created constructor function of the move will be named "mscale". This is all open to discussion, as long as we are consistent in naming the classes. I think it is important to name things in the front end (the language) and the back end similarly, decreasing the threshold for someone wanting to explore or contribute to the source code.
>
>     That was the short introduction. I will be starting to commit the code now; this should be the last time I commit a large chunk of code at the same time. I will be trying to get rid now of the most obviously redundant code but there will unfortunately be some work in adapting old code that is probably best done by you. I started working on old code a few weeks ago but I stopped when I felt I was spending a lot of time adapting code that was likely to be dead or doomed anyway.
>
>     I am still struggling with understanding all aspects of cmake. It appears that I need to modify all the CMakeList files manually, is that the way it is supposed to be? If so, I would prefer to have the files more nicely organized, for instance with one file per line, like I am doing for the parser test code.
>
>
>     Best,
>
>     Fredrik
>
>
